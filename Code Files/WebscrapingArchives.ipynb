{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# Function to scrape email contents and organize them into a DataFrame\n",
        "def scrape_email_contents(url):\n",
        "    # Send a GET request to the URL\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Check if the request was successful (status code 200)\n",
        "    if response.status_code == 200:\n",
        "        # Parse the HTML content of the page\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        # Find all <div> tags with class=\"section\"\n",
        "        sections = soup.find_all('div', class_='section')\n",
        "\n",
        "        # Initialize an empty list to store extracted contents\n",
        "        contents_list = []\n",
        "\n",
        "        # Loop through each section\n",
        "        for section in sections:\n",
        "            # Find all <p> tags within the section\n",
        "            paragraphs = section.find_all('p')\n",
        "\n",
        "            # Extract text from each <p> tag and append to the list\n",
        "            contents = [p.get_text(strip=True) for p in paragraphs]\n",
        "            contents_list.append(contents)\n",
        "\n",
        "        # Create a DataFrame from the list of contents\n",
        "        df = pd.DataFrame(contents_list, columns=[f'Column_{i}' for i in range(len(contents_list[0]))])\n",
        "        return df\n",
        "    else:\n",
        "        print(\"Failed to retrieve the page. Status code:\", response.status_code)\n",
        "        return None\n",
        "\n",
        "# URL of the page to scrape\n",
        "url = \"https://webaim.org/discussion/mail_thread?thread=11029\"\n",
        "\n",
        "# Call the function to scrape contents and create a DataFrame\n",
        "email_df = scrape_email_contents(url)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(email_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tf9kV-KJTUK7",
        "outputId": "19a97253-dc0d-4637-e532-9bb69a961621"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                         Column_0  \\\n",
            "0  Search E-mail List Archivesfor   \n",
            "\n",
            "                                            Column_1  \\\n",
            "0  Number of posts in this thread: 8 (In chronolo...   \n",
            "\n",
            "                                            Column_2  \\\n",
            "0  From:Mike WarnerDate:Sat, Apr 06 2024 7:29PMSu...   \n",
            "\n",
            "                                            Column_3  \\\n",
            "0  Hi,I've recently built an interactive transcri...   \n",
            "\n",
            "                                            Column_4  \\\n",
            "0  From:Dean.Vasile@outlook.comDate:Sat, Apr 06 2...   \n",
            "\n",
            "                                            Column_5  \\\n",
            "0  Providing a way for assistive tech and keyboar...   \n",
            "\n",
            "                                            Column_6  \\\n",
            "0  From:David Engebretson Jr.Date:Sat, Apr 06 202...   \n",
            "\n",
            "                                            Column_7  \\\n",
            "0  I'm not sure if AblePlayer has industry standa...   \n",
            "\n",
            "                                            Column_8  \\\n",
            "0  From:L SniderDate:Sun, Apr 07 2024 7:58AMSubje...   \n",
            "\n",
            "                                            Column_9  \\\n",
            "0  I echo David, AblePlayer was very accessible i...   \n",
            "\n",
            "                                           Column_10  \\\n",
            "0  From:Mike WarnerDate:Sun, Apr 07 2024 5:59PMSu...   \n",
            "\n",
            "                                           Column_11  \\\n",
            "0  I did look at Able Player after I built my sol...   \n",
            "\n",
            "                                           Column_12  \\\n",
            "0  From:David Engebretson Jr.Date:Sun, Apr 07 202...   \n",
            "\n",
            "                                           Column_13  \\\n",
            "0  Oh darn, maybe I misunderstood. I thought you ...   \n",
            "\n",
            "                                           Column_14  \\\n",
            "0  From:Geethavani.ShamannaDate:Mon, Apr 08 2024 ...   \n",
            "\n",
            "                                           Column_15  \\\n",
            "0  It would also be useful if you provide an opti...   \n",
            "\n",
            "                                           Column_16  \\\n",
            "0  From:Mike WarnerDate:Mon, Apr 08 2024 10:48AMS...   \n",
            "\n",
            "                                           Column_17  \n",
            "0  After re-reading the suggestions, I'lll use F3...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# Function to scrape email contents and organize them into a DataFrame\n",
        "def scrape_email_contents(thread_number):\n",
        "    # Generate URL based on the thread number\n",
        "    url = f\"https://webaim.org/discussion/mail_thread?thread={thread_number}\"\n",
        "\n",
        "    # Send a GET request to the URL\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Check if the request was successful (status code 200)\n",
        "    if response.status_code == 200:\n",
        "        # Parse the HTML content of the page\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        # Find all <div> tags with class=\"section\"\n",
        "        sections = soup.find_all('div', class_='section')\n",
        "\n",
        "        # Initialize an empty list to store extracted contents\n",
        "        contents_list = []\n",
        "\n",
        "        # Loop through each section\n",
        "        for section in sections:\n",
        "            # Find all <p> tags within the section\n",
        "            paragraphs = section.find_all('p')\n",
        "\n",
        "            # Extract text from each <p> tag and append to the list\n",
        "            contents = [p.get_text(strip=True) for p in paragraphs]\n",
        "            contents_list.append(contents)\n",
        "\n",
        "        # Create a DataFrame from the list of contents\n",
        "        df = pd.DataFrame(contents_list, columns=[f'Column_{i}' for i in range(len(contents_list[0]))])\n",
        "        return df\n",
        "    else:\n",
        "        print(\"Failed to retrieve the page. Status code:\", response.status_code)\n",
        "        return None\n",
        "\n",
        "# Function to scrape data from multiple pages and store in a DataFrame\n",
        "def scrape_multiple_pages(num_pages):\n",
        "    # Initialize an empty DataFrame\n",
        "    df_combined = pd.DataFrame()\n",
        "\n",
        "    # Loop through a range of thread numbers\n",
        "    for thread_number in range(11029, 11029 - num_pages, -1):\n",
        "        # Call the function to scrape contents for the current page\n",
        "        email_df = scrape_email_contents(thread_number)\n",
        "\n",
        "        # Append the DataFrame to the combined DataFrame\n",
        "        df_combined = pd.concat([df_combined, email_df], ignore_index=True)\n",
        "\n",
        "    return df_combined\n",
        "\n",
        "# Number of pages to scrape\n",
        "num_pages = 10\n",
        "\n",
        "# Call the function to scrape data from multiple pages and store in a DataFrame\n",
        "result_df = scrape_multiple_pages(num_pages)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(result_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyieJZD2U3VS",
        "outputId": "0d305353-dbb2-4c61-bd41-dc4b4777c47b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                         Column_0  \\\n",
            "0  Search E-mail List Archivesfor   \n",
            "1  Search E-mail List Archivesfor   \n",
            "2  Search E-mail List Archivesfor   \n",
            "3  Search E-mail List Archivesfor   \n",
            "4  Search E-mail List Archivesfor   \n",
            "5  Search E-mail List Archivesfor   \n",
            "6  Search E-mail List Archivesfor   \n",
            "7  Search E-mail List Archivesfor   \n",
            "8  Search E-mail List Archivesfor   \n",
            "9  Search E-mail List Archivesfor   \n",
            "\n",
            "                                            Column_1  \\\n",
            "0  Number of posts in this thread: 8 (In chronolo...   \n",
            "1  Number of posts in this thread: 8 (In chronolo...   \n",
            "2  Number of posts in this thread: 2 (In chronolo...   \n",
            "3  Number of posts in this thread: 1 (In chronolo...   \n",
            "4  Number of posts in this thread: 2 (In chronolo...   \n",
            "5  Number of posts in this thread: 0 (In chronolo...   \n",
            "6  Number of posts in this thread: 7 (In chronolo...   \n",
            "7  Number of posts in this thread: 0 (In chronolo...   \n",
            "8  Number of posts in this thread: 11 (In chronol...   \n",
            "9  Number of posts in this thread: 7 (In chronolo...   \n",
            "\n",
            "                                            Column_2  \\\n",
            "0  From:Mike WarnerDate:Sat, Apr 06 2024 7:29PMSu...   \n",
            "1  From:Brian LovelyDate:Wed, Apr 03 2024 7:23AMS...   \n",
            "2  From:Howard KramerDate:Mon, Apr 01 2024 4:59PM...   \n",
            "3  From:Rob Carr Jr.Date:Mon, Apr 01 2024 9:43AMS...   \n",
            "4  From:Duff JohnsonDate:Mon, Apr 01 2024 7:39AMS...   \n",
            "5                                                NaN   \n",
            "6  From:Mike WarnerDate:Tue, Mar 26 2024 7:45AMSu...   \n",
            "7                                                NaN   \n",
            "8  From:Hatfield, EvanDate:Mon, Mar 25 2024 12:00...   \n",
            "9  From:Schafer, CarmenDate:Mon, Mar 25 2024 11:3...   \n",
            "\n",
            "                                            Column_3  \\\n",
            "0  Hi,I've recently built an interactive transcri...   \n",
            "1  I'm looking for online digital accessibility t...   \n",
            "2  *Accessing Higher Ground: Accessible Media, We...   \n",
            "3  Good day all!The 2024 WebAIM Million report ha...   \n",
            "4  All,Following the publication of WTPDF and PDF...   \n",
            "5                                                NaN   \n",
            "6  Hi all,we use MathJax for our MathML math.  JA...   \n",
            "7                                                NaN   \n",
            "8  Hello, WebAIM Nation -My colleagues and I work...   \n",
            "9  Hi everyone,We have a third-party web app that...   \n",
            "\n",
            "                                            Column_4  \\\n",
            "0  From:Dean.Vasile@outlook.comDate:Sat, Apr 06 2...   \n",
            "1  From:Geethavani.ShamannaDate:Wed, Apr 03 2024 ...   \n",
            "2  From:Howard KramerDate:Fri, Apr 05 2024 12:59P...   \n",
            "3                                                NaN   \n",
            "4  From:Duff JohnsonDate:Mon, Apr 01 2024 7:50AMS...   \n",
            "5                                                NaN   \n",
            "6  From:Hayman, DouglassDate:Tue, Mar 26 2024 8:1...   \n",
            "7                                                NaN   \n",
            "8  From:Hayman, DouglassDate:Mon, Mar 25 2024 12:...   \n",
            "9  From:Steve GreenDate:Mon, Mar 25 2024 12:05PMS...   \n",
            "\n",
            "                                            Column_5  \\\n",
            "0  Providing a way for assistive tech and keyboar...   \n",
            "1  Have you tried Deque University?https://dequeu...   \n",
            "2  *Accessing Higher Ground: Accessible Media, We...   \n",
            "3                                                NaN   \n",
            "4  All,Following the publication of WTPDF and PDF...   \n",
            "5                                                NaN   \n",
            "6  Mike,Don't know if this will be helpful in tro...   \n",
            "7                                                NaN   \n",
            "8  I'd recommend using NVDA in Windows.  While JA...   \n",
            "9  The Understanding page states that SC 3.3.2 on...   \n",
            "\n",
            "                                            Column_6  \\\n",
            "0  From:David Engebretson Jr.Date:Sat, Apr 06 202...   \n",
            "1  From:Jano Llorca LisDate:Wed, Apr 03 2024 7:42...   \n",
            "2                                                NaN   \n",
            "3                                                NaN   \n",
            "4                                                NaN   \n",
            "5                                                NaN   \n",
            "6  From:Dean.Vasile@outlook.comDate:Tue, Mar 26 2...   \n",
            "7                                                NaN   \n",
            "8  From:Dean.Vasile@outlook.comDate:Mon, Mar 25 2...   \n",
            "9  From:Patrick H. LaukeDate:Mon, Mar 25 2024 12:...   \n",
            "\n",
            "                                            Column_7  \\\n",
            "0  I'm not sure if AblePlayer has industry standa...   \n",
            "1  For me, the best training is at Deque Universi...   \n",
            "2                                                NaN   \n",
            "3                                                NaN   \n",
            "4                                                NaN   \n",
            "5                                                NaN   \n",
            "6  Good morning MikeI donât know if this will h...   \n",
            "7                                                NaN   \n",
            "8  I'm not sure about any restrictions for jaws t...   \n",
            "9  3.3.2 Labels or Instructions is aimed at contr...   \n",
            "\n",
            "                                            Column_8  \\\n",
            "0  From:L SniderDate:Sun, Apr 07 2024 7:58AMSubje...   \n",
            "1  From:Dean.Vasile@outlook.comDate:Wed, Apr 03 2...   \n",
            "2                                                NaN   \n",
            "3                                                NaN   \n",
            "4                                                NaN   \n",
            "5                                                NaN   \n",
            "6  From:David FaroughDate:Tue, Mar 26 2024 11:35A...   \n",
            "7                                                NaN   \n",
            "8  From:Hayman, DouglassDate:Mon, Mar 25 2024 12:...   \n",
            "9  From:Schafer, CarmenDate:Mon, Mar 25 2024 12:2...   \n",
            "\n",
            "                                            Column_9  ...  \\\n",
            "0  I echo David, AblePlayer was very accessible i...  ...   \n",
            "1  Hello BryanI have seen a couple of responses m...  ...   \n",
            "2                                                NaN  ...   \n",
            "3                                                NaN  ...   \n",
            "4                                                NaN  ...   \n",
            "5                                                NaN  ...   \n",
            "6  I hope some of the following resources will he...  ...   \n",
            "7                                                NaN  ...   \n",
            "8  Dean,Perhaps things changed.  I thought that a...  ...   \n",
            "9                                   Thank you, both!  ...   \n",
            "\n",
            "                                           Column_14  \\\n",
            "0  From:Geethavani.ShamannaDate:Mon, Apr 08 2024 ...   \n",
            "1  From:Kavein ThranDate:Sun, Apr 07 2024 7:37AMS...   \n",
            "2                                                NaN   \n",
            "3                                                NaN   \n",
            "4                                                NaN   \n",
            "5                                                NaN   \n",
            "6  From:Mike WarnerDate:Mon, Apr 01 2024 12:52PMS...   \n",
            "7                                                NaN   \n",
            "8  From:Dean.Vasile@outlook.comDate:Mon, Mar 25 2...   \n",
            "9  From:Brooks NewtonDate:Wed, Apr 03 2024 9:50AM...   \n",
            "\n",
            "                                           Column_15  \\\n",
            "0  It would also be useful if you provide an opti...   \n",
            "1  HiI just enrolled in the Sara Soueidan Practic...   \n",
            "2                                                NaN   \n",
            "3                                                NaN   \n",
            "4                                                NaN   \n",
            "5                                                NaN   \n",
            "6  Thank you, Jim!  That did it.  I'll add that t...   \n",
            "7                                                NaN   \n",
            "8  If youâre paying the hundred dollars a year ...   \n",
            "9  Hi Dean,Thanks for your email and for letting ...   \n",
            "\n",
            "                                           Column_16  \\\n",
            "0  From:Mike WarnerDate:Mon, Apr 08 2024 10:48AMS...   \n",
            "1  From:George Joeckel IIIDate:Tue, Apr 09 2024 1...   \n",
            "2                                                NaN   \n",
            "3                                                NaN   \n",
            "4                                                NaN   \n",
            "5                                                NaN   \n",
            "6                                                NaN   \n",
            "7                                                NaN   \n",
            "8  From:tim.harshbarger@deque.comDate:Tue, Mar 26...   \n",
            "9                                                NaN   \n",
            "\n",
            "                                           Column_17  \\\n",
            "0  After re-reading the suggestions, I'lll use F3...   \n",
            "1  Hi Bryan,WebAIM's online course Accessible Doc...   \n",
            "2                                                NaN   \n",
            "3                                                NaN   \n",
            "4                                                NaN   \n",
            "5                                                NaN   \n",
            "6                                                NaN   \n",
            "7                                                NaN   \n",
            "8  I want to offer some general advice about scre...   \n",
            "9                                                NaN   \n",
            "\n",
            "                                           Column_18  \\\n",
            "0                                                NaN   \n",
            "1                                                NaN   \n",
            "2                                                NaN   \n",
            "3                                                NaN   \n",
            "4                                                NaN   \n",
            "5                                                NaN   \n",
            "6                                                NaN   \n",
            "7                                                NaN   \n",
            "8  From:Dean.Vasile@outlook.comDate:Tue, Mar 26 2...   \n",
            "9                                                NaN   \n",
            "\n",
            "                                           Column_19  \\\n",
            "0                                                NaN   \n",
            "1                                                NaN   \n",
            "2                                                NaN   \n",
            "3                                                NaN   \n",
            "4                                                NaN   \n",
            "5                                                NaN   \n",
            "6                                                NaN   \n",
            "7                                                NaN   \n",
            "8  Tim, that is excellent advice.I just want to a...   \n",
            "9                                                NaN   \n",
            "\n",
            "                                           Column_20  \\\n",
            "0                                                NaN   \n",
            "1                                                NaN   \n",
            "2                                                NaN   \n",
            "3                                                NaN   \n",
            "4                                                NaN   \n",
            "5                                                NaN   \n",
            "6                                                NaN   \n",
            "7                                                NaN   \n",
            "8  From:Mosley, LeighDate:Tue, Mar 26 2024 8:17AM...   \n",
            "9                                                NaN   \n",
            "\n",
            "                                           Column_21  \\\n",
            "0                                                NaN   \n",
            "1                                                NaN   \n",
            "2                                                NaN   \n",
            "3                                                NaN   \n",
            "4                                                NaN   \n",
            "5                                                NaN   \n",
            "6                                                NaN   \n",
            "7                                                NaN   \n",
            "8  Hello all,I admit this email thread caught me ...   \n",
            "9                                                NaN   \n",
            "\n",
            "                                           Column_22  \\\n",
            "0                                                NaN   \n",
            "1                                                NaN   \n",
            "2                                                NaN   \n",
            "3                                                NaN   \n",
            "4                                                NaN   \n",
            "5                                                NaN   \n",
            "6                                                NaN   \n",
            "7                                                NaN   \n",
            "8  From:Andrews, David B (DEED)Date:Tue, Mar 26 2...   \n",
            "9                                                NaN   \n",
            "\n",
            "                                           Column_23  \n",
            "0                                                NaN  \n",
            "1                                                NaN  \n",
            "2                                                NaN  \n",
            "3                                                NaN  \n",
            "4                                                NaN  \n",
            "5                                                NaN  \n",
            "6                                                NaN  \n",
            "7                                                NaN  \n",
            "8  It seems to me that if you are using JAWS in 4...  \n",
            "9                                                NaN  \n",
            "\n",
            "[10 rows x 24 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_df.to_csv('Email Archives Data.csv')"
      ],
      "metadata": {
        "id": "LCSjme2VVUSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# Function to scrape email contents and organize them into a DataFrame\n",
        "def scrape_email_contents(thread_number):\n",
        "    # Generate URL based on the thread number\n",
        "    url = f\"https://webaim.org/discussion/mail_thread?thread={thread_number}\"\n",
        "\n",
        "    # Send a GET request to the URL\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Check if the request was successful (status code 200)\n",
        "    if response.status_code == 200:\n",
        "        # Parse the HTML content of the page\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        # Find all <div> tags with class=\"section\"\n",
        "        sections = soup.find_all('div', class_='section')\n",
        "\n",
        "        # Initialize an empty list to store extracted contents\n",
        "        contents_list = []\n",
        "\n",
        "        # Loop through each section\n",
        "        for section in sections:\n",
        "            # Find all <p> tags within the section\n",
        "            paragraphs = section.find_all('p')\n",
        "\n",
        "            # Extract text from each <p> tag and append to the list\n",
        "            contents = [p.get_text(strip=True) for p in paragraphs]\n",
        "            contents_list.append(contents)\n",
        "\n",
        "        # Create a DataFrame from the list of contents\n",
        "        df = pd.DataFrame(contents_list, columns=[f'Column_{i}' for i in range(len(contents_list[0]))])\n",
        "        return df\n",
        "    else:\n",
        "        print(\"Failed to retrieve the page. Status code:\", response.status_code)\n",
        "        return None\n",
        "\n",
        "# Function to scrape data from multiple pages and store in a DataFrame\n",
        "def scrape_multiple_pages():\n",
        "    # Initialize an empty DataFrame\n",
        "    df_combined = pd.DataFrame()\n",
        "\n",
        "    # Initialize thread number\n",
        "    thread_number = 11029\n",
        "\n",
        "    # Loop until thread number becomes 0 or negative\n",
        "    while thread_number > 0:\n",
        "        # Call the function to scrape contents for the current page\n",
        "        email_df = scrape_email_contents(thread_number)\n",
        "\n",
        "        # Append the DataFrame to the combined DataFrame\n",
        "        if email_df is not None:\n",
        "            df_combined = pd.concat([df_combined, email_df], ignore_index=True)\n",
        "\n",
        "        # Decrease thread number for the next page\n",
        "        thread_number -= 1\n",
        "\n",
        "    return df_combined\n",
        "\n",
        "# Call the function to scrape data from multiple pages and store in a DataFrame\n",
        "result_df = scrape_multiple_pages()\n",
        "\n",
        "# Display the DataFrame\n",
        "print(result_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5Zwbs6oWGho",
        "outputId": "4cb4a597-fb0a-4148-c622-51f44f012bf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                             Column_0  \\\n",
            "0      Search E-mail List Archivesfor   \n",
            "1      Search E-mail List Archivesfor   \n",
            "2      Search E-mail List Archivesfor   \n",
            "3      Search E-mail List Archivesfor   \n",
            "4      Search E-mail List Archivesfor   \n",
            "...                               ...   \n",
            "11024  Search E-mail List Archivesfor   \n",
            "11025  Search E-mail List Archivesfor   \n",
            "11026  Search E-mail List Archivesfor   \n",
            "11027  Search E-mail List Archivesfor   \n",
            "11028  Search E-mail List Archivesfor   \n",
            "\n",
            "                                                Column_1  \\\n",
            "0      Number of posts in this thread: 8 (In chronolo...   \n",
            "1      Number of posts in this thread: 8 (In chronolo...   \n",
            "2      Number of posts in this thread: 2 (In chronolo...   \n",
            "3      Number of posts in this thread: 1 (In chronolo...   \n",
            "4      Number of posts in this thread: 2 (In chronolo...   \n",
            "...                                                  ...   \n",
            "11024  Number of posts in this thread: 7 (In chronolo...   \n",
            "11025  Number of posts in this thread: 1 (In chronolo...   \n",
            "11026  Number of posts in this thread: 1 (In chronolo...   \n",
            "11027  Number of posts in this thread: 1 (In chronolo...   \n",
            "11028  Number of posts in this thread: 1 (In chronolo...   \n",
            "\n",
            "                                                Column_2  \\\n",
            "0      From:Mike WarnerDate:Sat, Apr 06 2024 7:29PMSu...   \n",
            "1      From:Brian LovelyDate:Wed, Apr 03 2024 7:23AMS...   \n",
            "2      From:Howard KramerDate:Mon, Apr 01 2024 4:59PM...   \n",
            "3      From:Rob Carr Jr.Date:Mon, Apr 01 2024 9:43AMS...   \n",
            "4      From:Duff JohnsonDate:Mon, Apr 01 2024 7:39AMS...   \n",
            "...                                                  ...   \n",
            "11024  From:Paul BohmanDate:Tue, Feb 08 2000 7:23PMSu...   \n",
            "11025  From:Crystal AllenDate:Mon, Jan 24 2000 3:03PM...   \n",
            "11026  From:Paul BohmanDate:Thu, Jan 13 2000 11:05AMS...   \n",
            "11027  From:Crystal AllenDate:Mon, Nov 01 1999 4:52PM...   \n",
            "11028  From:Paul BohmanDate:Mon, Nov 01 1999 4:40PMSu...   \n",
            "\n",
            "                                                Column_3  \\\n",
            "0      Hi,I've recently built an interactive transcri...   \n",
            "1      I'm looking for online digital accessibility t...   \n",
            "2      *Accessing Higher Ground: Accessible Media, We...   \n",
            "3      Good day all!The 2024 WebAIM Million report ha...   \n",
            "4      All,Following the publication of WTPDF and PDF...   \n",
            "...                                                  ...   \n",
            "11024  Although we have taken steps to make sure that...   \n",
            "11025  Note the link on the WebAIM homepage that addr...   \n",
            "11026  Recently, I was asked to make a list of the \"e...   \n",
            "11027  I came across an interesting site that I have ...   \n",
            "11028  To the \"Web Accessibility in Mind\" listserv:Th...   \n",
            "\n",
            "                                                Column_4  \\\n",
            "0      From:Dean.Vasile@outlook.comDate:Sat, Apr 06 2...   \n",
            "1      From:Geethavani.ShamannaDate:Wed, Apr 03 2024 ...   \n",
            "2      From:Howard KramerDate:Fri, Apr 05 2024 12:59P...   \n",
            "3                                                    NaN   \n",
            "4      From:Duff JohnsonDate:Mon, Apr 01 2024 7:50AMS...   \n",
            "...                                                  ...   \n",
            "11024  From:Prof Norm CoombsDate:Tue, Feb 08 2000 7:2...   \n",
            "11025                                                NaN   \n",
            "11026                                                NaN   \n",
            "11027                                                NaN   \n",
            "11028                                                NaN   \n",
            "\n",
            "                                                Column_5  \\\n",
            "0      Providing a way for assistive tech and keyboar...   \n",
            "1      Have you tried Deque University?https://dequeu...   \n",
            "2      *Accessing Higher Ground: Accessible Media, We...   \n",
            "3                                                    NaN   \n",
            "4      All,Following the publication of WTPDF and PDF...   \n",
            "...                                                  ...   \n",
            "11024  Hi Paul and all:I am not sure I can explain th...   \n",
            "11025                                                NaN   \n",
            "11026                                                NaN   \n",
            "11027                                                NaN   \n",
            "11028                                                NaN   \n",
            "\n",
            "                                                Column_6  \\\n",
            "0      From:David Engebretson Jr.Date:Sat, Apr 06 202...   \n",
            "1      From:Jano Llorca LisDate:Wed, Apr 03 2024 7:42...   \n",
            "2                                                    NaN   \n",
            "3                                                    NaN   \n",
            "4                                                    NaN   \n",
            "...                                                  ...   \n",
            "11024  From:DarenDate:Wed, Feb 09 2000 8:33AMSubject:...   \n",
            "11025                                                NaN   \n",
            "11026                                                NaN   \n",
            "11027                                                NaN   \n",
            "11028                                                NaN   \n",
            "\n",
            "                                                Column_7  \\\n",
            "0      I'm not sure if AblePlayer has industry standa...   \n",
            "1      For me, the best training is at Deque Universi...   \n",
            "2                                                    NaN   \n",
            "3                                                    NaN   \n",
            "4                                                    NaN   \n",
            "...                                                  ...   \n",
            "11024  What kind of screen reader is being used in th...   \n",
            "11025                                                NaN   \n",
            "11026                                                NaN   \n",
            "11027                                                NaN   \n",
            "11028                                                NaN   \n",
            "\n",
            "                                                Column_8  \\\n",
            "0      From:L SniderDate:Sun, Apr 07 2024 7:58AMSubje...   \n",
            "1      From:Dean.Vasile@outlook.comDate:Wed, Apr 03 2...   \n",
            "2                                                    NaN   \n",
            "3                                                    NaN   \n",
            "4                                                    NaN   \n",
            "...                                                  ...   \n",
            "11024  From:Prof Norm CoombsDate:Wed, Feb 09 2000 9:0...   \n",
            "11025                                                NaN   \n",
            "11026                                                NaN   \n",
            "11027                                                NaN   \n",
            "11028                                                NaN   \n",
            "\n",
            "                                                Column_9  ... Column_154  \\\n",
            "0      I echo David, AblePlayer was very accessible i...  ...        NaN   \n",
            "1      Hello BryanI have seen a couple of responses m...  ...        NaN   \n",
            "2                                                    NaN  ...        NaN   \n",
            "3                                                    NaN  ...        NaN   \n",
            "4                                                    NaN  ...        NaN   \n",
            "...                                                  ...  ...        ...   \n",
            "11024  The screen reader is JFW Jaws for windows runn...  ...        NaN   \n",
            "11025                                                NaN  ...        NaN   \n",
            "11026                                                NaN  ...        NaN   \n",
            "11027                                                NaN  ...        NaN   \n",
            "11028                                                NaN  ...        NaN   \n",
            "\n",
            "      Column_155 Column_156 Column_157 Column_158 Column_159 Column_160  \\\n",
            "0            NaN        NaN        NaN        NaN        NaN        NaN   \n",
            "1            NaN        NaN        NaN        NaN        NaN        NaN   \n",
            "2            NaN        NaN        NaN        NaN        NaN        NaN   \n",
            "3            NaN        NaN        NaN        NaN        NaN        NaN   \n",
            "4            NaN        NaN        NaN        NaN        NaN        NaN   \n",
            "...          ...        ...        ...        ...        ...        ...   \n",
            "11024        NaN        NaN        NaN        NaN        NaN        NaN   \n",
            "11025        NaN        NaN        NaN        NaN        NaN        NaN   \n",
            "11026        NaN        NaN        NaN        NaN        NaN        NaN   \n",
            "11027        NaN        NaN        NaN        NaN        NaN        NaN   \n",
            "11028        NaN        NaN        NaN        NaN        NaN        NaN   \n",
            "\n",
            "      Column_161 Column_162 Column_163  \n",
            "0            NaN        NaN        NaN  \n",
            "1            NaN        NaN        NaN  \n",
            "2            NaN        NaN        NaN  \n",
            "3            NaN        NaN        NaN  \n",
            "4            NaN        NaN        NaN  \n",
            "...          ...        ...        ...  \n",
            "11024        NaN        NaN        NaN  \n",
            "11025        NaN        NaN        NaN  \n",
            "11026        NaN        NaN        NaN  \n",
            "11027        NaN        NaN        NaN  \n",
            "11028        NaN        NaN        NaN  \n",
            "\n",
            "[11029 rows x 164 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_df.to_csv('All_Email_Archives_Data.csv', index=False, escapechar='\\\\')"
      ],
      "metadata": {
        "id": "RJ7ug0aQfmnP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}